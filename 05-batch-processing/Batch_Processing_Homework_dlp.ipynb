{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6711f49-5bbb-4171-9484-fd57639d8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37b7598d-5eb7-4f87-a4c4-2ad4d74b5880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/11 05:51:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/11 05:51:32 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a3ccc-2faf-4f7d-bf21-2d3be67d529b",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1935fd5-fee4-4679-929a-c375ee9ea0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df_yellow = spark.read.parquet('../data/raw/yellow/2024/10/yellow_tripdata_2024-10.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94c51f12-d87b-4d91-b476-c2fdd6076eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_yellow.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65240184-f54b-4791-b262-d487e084e368",
   "metadata": {},
   "source": [
    "### Partition data and write it to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644d91ae-2ef9-49e2-936d-a0559103e5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data for 2024/10\n",
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "year = 2024\n",
    "month = 10\n",
    "print(f'processing data for {year}/{month}')\n",
    "\n",
    "input_path = f'../data/raw/yellow/{year}/{month:02d}/yellow_tripdata_{year}-{month:02d}.parquet'\n",
    "output_path = f'../data/pq/yellow/{year}/{month:02d}/'\n",
    "\n",
    "df_yellow = spark.read.parquet(input_path)\n",
    "df_yellow.printSchema()\n",
    "\n",
    "df_yellow \\\n",
    "    .repartition(4) \\\n",
    "    .write.parquet(output_path, mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2470690b-6628-4402-9084-0f8ec3643950",
   "metadata": {},
   "source": [
    "# Use SQL with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d39fa48-b756-46d7-ab4a-bab0cd3ab647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.createOrReplaceTempView('yellow_trips_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f72511-801c-414c-805a-e752a4abd751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  128893|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    count(1)\n",
    "FROM\n",
    "    yellow_trips_data\n",
    "WHERE\n",
    "    tpep_pickup_datetime >= '2024-10-15' AND\n",
    "    tpep_pickup_datetime < '2024-10-16'    \n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392c9ae5-7f64-4cbf-a5aa-1be6a163749f",
   "metadata": {},
   "source": [
    "# Longest distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a80930ce-4195-4cc4-bd30-c831ad565d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+\n",
      "|trip_distance|trip_duration_h|\n",
      "+-------------+---------------+\n",
      "|          0.0|            143|\n",
      "|         0.96|             26|\n",
      "|         1.91|             23|\n",
      "|         1.93|             23|\n",
      "|         2.52|             23|\n",
      "|         5.32|             23|\n",
      "|         0.73|             23|\n",
      "|        18.58|             23|\n",
      "|         1.49|             23|\n",
      "|          0.7|             23|\n",
      "|         2.21|             23|\n",
      "|         3.37|             23|\n",
      "|         1.95|             23|\n",
      "|         1.06|             23|\n",
      "|         3.29|             23|\n",
      "|         4.57|             23|\n",
      "|         1.55|             23|\n",
      "|         0.82|             23|\n",
      "|        14.24|             23|\n",
      "|         1.98|             23|\n",
      "+-------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    trip_distance,\n",
    "    DATEDIFF(hour, tpep_pickup_datetime, tpep_dropoff_datetime) as trip_duration_h\n",
    "FROM\n",
    "    yellow_trips_data\n",
    "SORT BY trip_duration_h DESC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdd8ca6-4d4e-4c25-9668-11590e2b92df",
   "metadata": {},
   "source": [
    "# Longest Duration in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d7ee8aa-b671-47c7-9956-b14b15ed9de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:==============>                                           (1 + 3) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|max_date_diff|\n",
      "+-------------+\n",
      "|          162|\n",
      "+-------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    MAX(DATEDIFF(hour, tpep_pickup_datetime, tpep_dropoff_datetime)) AS max_date_diff\n",
    "FROM\n",
    "    yellow_trips_data\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8281f-111d-494b-a33e-948e9f72b292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
